---
title: "SCiL - Final"
author: "Amanda Doucette"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE)
knitr::opts_knit$set(root.dir = '~/McGill/projects/eval2/eval2')
library(tidyverse)
library(ggthemes)
library(lme4)
library(sjPlot)
library(ggeffects)
library(RColorBrewer)
library(dagitty)
library(broom.mixed)
```

```{r funcs}
transform_data <- function(d) {
  d <- d %>% group_by(lang) %>% mutate(
    mean_mi = mean(morph_complexity),
    mean_omi = mean(ortho_morph_complexity),
    mean_pc = mean(phon_loss),
    mean_wl = mean(phon_len),
    mean_fr = mean(log(freq)),
    n = n(),
  ) %>% ungroup()
  
  d <-  d %>% group_by(lang, base) %>% mutate(
    lemma_mi = mean(morph_complexity),
    lemma_omi = mean(ortho_morph_complexity)
  ) %>% ungroup()

  d <- d %>% mutate(
    phon_len_z = (phon_len - mean(phon_len)) / sd(phon_len),
    logfreq = log(freq),
    logfreq_z = (log(freq) - mean(log(freq))) / sd(log(freq)),
    morph_complexity_z = (morph_complexity - mean(morph_complexity)) / sd(morph_complexity),
    ortho_morph_complexity_z = (ortho_morph_complexity - mean(ortho_morph_complexity)) / sd(ortho_morph_complexity),
    phon_loss_z = (phon_loss - mean(phon_loss)) / sd(phon_loss),
    lemma_mi_z = (lemma_mi - mean(lemma_mi)) / sd(lemma_mi)
  )
  
  d <- d %>% group_by(lang) %>% mutate(
    mean_mi_z = mean(morph_complexity_z),
    mean_omi_z = mean(ortho_morph_complexity_z),
    mean_pc_z = mean(phon_loss_z),
    mean_wl_z = mean(phon_len_z),
    mean_fr_z = mean(logfreq_z),
    n = n()
  ) %>% ungroup()
  return(d)
}

group_by_base <- function(d) {
  bases <- d %>% group_by(lang, base) %>% summarise(
    morph_complexity = mean(morph_complexity),
    ortho_morph_complexity = mean(ortho_morph_complexity),
    phon_loss = mean(phon_loss),
    lang = first(lang),
    phon_len = mean(phon_len),
    simple_pos = first(simple_pos),
    freq = sum(freq),
  )
  return(bases)
}

plot_across_langs <- function(d, v1, v2, lab1 = "", lab2 = "") {
  v1col <- enquo(v1)
  v2col <- enquo(v2)
  dat <- d %>% group_by(lang) %>% summarise(
    mean_v1 = mean(!!v1col),
    mean_v2 = mean(!!v2col)
    )
  dat %>% ggplot(aes(x = mean_v1, y=mean_v2)) +
    geom_smooth(color = "#1A4571") +
    geom_smooth(method='lm', color = "#FF5A48") +
    geom_text(aes(label=lang)) +
    theme_hc() +
    xlab(lab1) +
    ylab(lab2)
}
```

```{r readdata}
exclude_langs = c("Bengali", "Cebuano", "Hindi", "Indonesian", "Kabardian", "Kashubian", "Kazakh", "Kyrgyz", "Maltese", "Maori", "Oromo", "Shona", "Swahili", "Tagalog", "Telugu", "Turkmen", "Urdu", "Uyghur", "Uzbek", "Chewa", "Tajik", "Gothic")

data <- read.csv('data/processed.tsv', sep='\t')

data$simple_pos <- data$pos
data$simple_pos <- case_match(
  data$simple_pos,
  "N" ~ "N",
  "V" ~ "V",
  "ADJ" ~ "ADJ",
  "V.CVB" ~ "V",
  "V.MSDR" ~ "V",
  "V.PTCP" ~ "V",
  .default = "X"
)
data$pos <- as.factor(data$pos)
data$simple_pos <- as.factor(data$simple_pos)

data$lang <- case_match(
  data$lang,
  'amh' ~ 'Amharic',
  'aze' ~ 'Azerbaijani',
  'ben' ~ 'Bengali',
  'cat' ~ 'Catalan',
  'ceb' ~ 'Cebuano',
  'ces' ~ 'Czech',
  'csb' ~ 'Kashubian',
  'deu' ~ 'German',
  'eng' ~ 'English',
  'fra' ~ 'French',
  'got' ~ 'Gothic',
  'hbs' ~ 'Serbo Croatian',
  'hin' ~ 'Hindi',
  'hun' ~ 'Hungarian',
  'ind' ~ 'Indonesian',
  'ita' ~ 'Italian',
  'kaz' ~ 'Kazakh',
  'kbd' ~ 'Kabardian',
  'khk' ~ 'Mongolian',
  'kir' ~ 'Kyrgyz',
  'mao' ~ 'Maori',
  'mlt' ~ 'Maltese',
  'nld' ~ 'Dutch',
  'nya' ~ 'Chewa',
  'ood' ~ 'O\'odham',
  'orm' ~ 'Oromo',
  'pol' ~ 'Polish', 
  'por' ~ 'Portuguese',
  'ron' ~ 'Romanian',
  'rus' ~ 'Russian',
  'sna' ~ 'Shona',
  'spa' ~ 'Spanish',
  'swc' ~ 'Swahili',
  'swe' ~ 'Swedish',
  'sqi' ~ 'Albanian',
  'tel' ~ 'Telugu',
  'tgk' ~ 'Tajik',
  'tgl' ~ 'Tagalog',
  'tuk' ~ 'Turkmen',
  'tur' ~ 'Turkish',
  'uig' ~ 'Uyghur',
  'ukr' ~ 'Ukrainian',
  'urd' ~ 'Urdu',
  'uzb' ~ 'Uzbek',
  'zul' ~ 'Zulu'
)
data <- data %>% filter(!(lang %in% exclude_langs))
data$lang <- as.factor(data$lang)
data <- data %>% filter(count > 0)
data <- data %>% filter(lang != 'O\'odham')
data <- data %>% filter(!is.na(phon_loss))
```

```{r datapim}
setwd('~/McGill/projects/eval2')
include_langs <- c("Albanian", "Amharic", "Azerbaijani", "Catalan", "Czech", "Dutch", "English", "French", "German", "Hungarian", "Italian", "Khalka Mongolian", "Polish", "Portuguese", "Romanian", "Russian", "Serbo Croatian", "Spanish", "Swedish", "Turkish", "Ukranian", "Zulu")

data_pim <- read.csv("pimentel/results/northeuralex/normal/orig/phoible__results-final.csv")
data_pim$lang <- case_match(
  data_pim$lang,
  'amh' ~ 'Amharic',
  'aze' ~ 'Azerbaijani',
  'ben' ~ 'Bengali',
  'cat' ~ 'Catalan',
  'ceb' ~ 'Cebuano',
  'ces' ~ 'Czech',
  'csb' ~ 'Kashubian',
  'deu' ~ 'German',
  'eng' ~ 'English',
  'fra' ~ 'French',
  'got' ~ 'Gothic',
  'hbs' ~ 'Serbo Croatian',
  'hin' ~ 'Hindi',
  'hun' ~ 'Hungarian',
  'ind' ~ 'Indonesian',
  'ita' ~ 'Italian',
  'kaz' ~ 'Kazakh',
  'kbd' ~ 'Kabardian',
  'khk' ~ 'Mongolian',
  'kir' ~ 'Kyrgyz',
  'mao' ~ 'Maori',
  'mlt' ~ 'Maltese',
  'nld' ~ 'Dutch',
  'nya' ~ 'Chewa',
  'ood' ~ 'O\'odham',
  'orm' ~ 'Oromo',
  'pol' ~ 'Polish', 
  'por' ~ 'Portuguese',
  'ron' ~ 'Romanian',
  'rus' ~ 'Russian',
  'sna' ~ 'Shona',
  'spa' ~ 'Spanish',
  'swc' ~ 'Swahili',
  'swe' ~ 'Swedish',
  'tel' ~ 'Telugu',
  'tgk' ~ 'Tajik',
  'tgl' ~ 'Tagalog',
  'tuk' ~ 'Turkmen',
  'tur' ~ 'Turkish',
  'uig' ~ 'Uyghur',
  'ukr' ~ 'Ukrainian',
  'urd' ~ 'Urdu',
  'uzb' ~ 'Uzbek',
  'zul' ~ 'Zulu',
  .default = data_pim$lang
)
data_pim <- data_pim %>% filter(lang %in% include_langs)
data_pim$lang <- as.factor(data_pim$lang)

data_words_pim <- read.csv("pimentel/results/northeuralex/normal/orig/phoible__results-per-word.csv")
data_words_pim$lang <- case_match(
  data_words_pim$lang,
  'sqi' ~ 'Albanian',
  'amh' ~ 'Amharic',
  'aze' ~ 'Azerbaijani',
  'ben' ~ 'Bengali',
  'cat' ~ 'Catalan',
  'ceb' ~ 'Cebuano',
  'ces' ~ 'Czech',
  'csb' ~ 'Kashubian',
  'deu' ~ 'German',
  'eng' ~ 'English',
  'fra' ~ 'French',
  'got' ~ 'Gothic',
  'hbs' ~ 'Serbo Croatian',
  'hin' ~ 'Hindi',
  'hun' ~ 'Hungarian',
  'ind' ~ 'Indonesian',
  'ita' ~ 'Italian',
  'kaz' ~ 'Kazakh',
  'kbd' ~ 'Kabardian',
  'khk' ~ 'Mongolian',
  'kir' ~ 'Kyrgyz',
  'mao' ~ 'Maori',
  'mlt' ~ 'Maltese',
  'nld' ~ 'Dutch',
  'nya' ~ 'Chewa',
  'ood' ~ 'O\'odham',
  'orm' ~ 'Oromo',
  'pol' ~ 'Polish', 
  'por' ~ 'Portuguese',
  'ron' ~ 'Romanian',
  'rus' ~ 'Russian',
  'sna' ~ 'Shona',
  'spa' ~ 'Spanish',
  'swc' ~ 'Swahili',
  'swe' ~ 'Swedish',
  'tel' ~ 'Telugu',
  'tgk' ~ 'Tajik',
  'tgl' ~ 'Tagalog',
  'tuk' ~ 'Turkmen',
  'tur' ~ 'Turkish',
  'uig' ~ 'Uyghur',
  'ukr' ~ 'Ukrainian',
  'urd' ~ 'Urdu',
  'uzb' ~ 'Uzbek',
  'zul' ~ 'Zulu',
  .default = data_words_pim$lang
)

data_words_pim <- data_words_pim %>% filter(lang %in% include_langs)
data_words_pim$lang <- as.factor(data_words_pim$lang)
```

```{r process-data}
data_g2p <- data %>% filter(morph_complexity != 'NA') %>% transform_data()

# data_ortho <- data %>% filter(ortho_morph_complexity != 'NA') %>% transform_data()

data_base_g2p <- group_by_base(data_g2p) %>% transform_data()

# data_base_ortho <- group_by_base(data_ortho) %>% transform_data()
```

```{r dag}
g <- dagitty( "dag {
  WL -> PC
  FR -> WL
  FR -> PC
  FR -> MI
  WL -> MI
}")

plot(graphLayout(g))

mipc <- adjustmentSets(g, "MI", "PC", effect="direct")
wlpc <- adjustmentSets(g, "WL", "PC", effect="direct")
frpc <- adjustmentSets(g, "FR", "PC", effect="direct")
frmi <- adjustmentSets(g, "FR", "MI", effect="direct")
frwl <- adjustmentSets(g, "FR", "WL", effect="direct")
wlmi <- adjustmentSets(g, "WL", "MI", effect="direct")
```

MI, PC {FR}

WL, PC {FR}

FR, PC {WL}

FR, MI {}

FR, WL {}

WL, MI {FR}

# Partial Correlations

```{r plot-by-lang}
model.by.lang <- function(data, f, param) {
  d <- data %>% group_by(lang) %>% do(
    tidy(lm(f, data = .), conf.int=T)
  ) %>% filter(term == param)
  d$Significant <- d$p.value<0.05
  d <- d %>% mutate(lang=factor(lang, levels=(d %>% arrange(estimate))$lang))
  return(d)
}

plot.by.lang <- function(d, title="") {
  ggplot() +
    geom_segment(
      data = d,
      aes(x=lang, xend=lang, y=0, yend=estimate),
      color="grey"
    ) +
    geom_errorbar(
      data = d,
      aes(x=lang, y=estimate, ymin=conf.low, ymax=conf.high),
      alpha = 0.8,
      width = 0.7,
      linewidth = 0.7,
      color = "#1A4571"
    ) +
    geom_point(
      data = d,
      aes(y=estimate, x=lang, shape=Significant),
      size = 2.5,
      stroke = 1.5,
      color = "#1A4571"
    ) +
    scale_shape_manual(values=c(4, 16)) +
    theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
    theme_hc() +
    xlab('Language') +
    ylab('Coefficient') +
    ggtitle(title)
}

plot.by.lang.sig <- function(d, title="") {
  ggplot() +
    geom_segment(
      data = d,
      aes(x=lang, xend=lang, y=0, yend=estimate),
      color="grey"
    ) +
    geom_errorbar(
      data = d,
      aes(x=lang, y=estimate, ymin=conf.low, ymax=conf.high),
      alpha = 0.8,
      width = 0.7,
      linewidth = 0.7,
      color = "#1A4571"
    ) +
    geom_point(
      data = d,
      aes(y=estimate, x=lang, shape=Significant),
      size = 2.5,
      stroke = 1.5,
      color = "#1A4571"
    ) +
    scale_shape_manual(values=c(16, 4)) +
    theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
    theme_hc() +
    xlab('Language') +
    ylab('Coefficient') +
    ggtitle(title)
}

plot.by.lang.2 <- function(d, d2, lab1, lab2, colora='#1A4571', colorb='#FF5A48', title="") {
  ggplot() +
    geom_segment(
      data = d,
      aes(x=lang, xend=lang, y=0, yend=estimate),
      color="grey"
    ) +
    geom_segment(
      data = d2,
      aes(x=lang, xend=lang, y=0, yend=estimate),
      color="grey"
    ) +
    geom_errorbar(
      data = d,
      aes(x=lang, y=estimate, ymin=conf.low, ymax=conf.high, color="a"),
      alpha = 0.8,
      width = 0.7,
      linewidth = 0.7
    ) +
    geom_errorbar(
      data = d2,
      aes(x=lang, y=estimate, ymin=conf.low, ymax=conf.high, color="b"),
      alpha = 0.8,
      width = 0.7,
      linewidth = 0.7
    ) +
    geom_point(
      data = d,
      aes(y=estimate, x=lang, shape=Significant, color="a"),
      size = 2.5,
      stroke = 1.5,
    ) +
    geom_point(
      data = d2,
      aes(y=estimate, x=lang, shape=Significant, color="b"),
      size = 2,
      stroke = 1.5,
    ) +
    scale_colour_manual(
      name = '', 
      values =c('a'=colora,'b'=colorb),
      labels = c(lab1, lab2)
    ) +
    scale_shape_manual(values=c(4, 16)) +
    theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
    theme_hc() +
    xlab('Language') +
    ylab('Coefficient') +
    ggtitle(title)
}

mi.pc <- model.by.lang(data_g2p, formula(morph_complexity_z ~ phon_loss_z + logfreq_z + phon_len_z), 'phon_loss_z')
mi.pc.lem <- model.by.lang(data_base_g2p, formula(morph_complexity_z ~ phon_loss_z + logfreq_z + phon_len_z), 'phon_loss_z')
plot.by.lang.2(mi.pc.lem, mi.pc, 'By Lexeme', 'By Word')
ggsave("figs-final/corr_mi_pc_g2p.png", width = 6, height = 4)

pc.wl <- model.by.lang(data_g2p, formula(phon_loss_z ~ phon_len_z), 'phon_len_z')
pc.wl.pim <- model.by.lang(data_words_pim, formula(phoneme_loss ~ phoneme_len), 'phoneme_len')
plot.by.lang.2(pc.wl.pim, pc.wl, 'Phonotactic Data', 'UniMorph Data', '#482C7B', '#FF6B00')
ggsave("figs-final/corr_pc_wl_g2p.png", width = 6, height = 4)

pc.fr <- model.by.lang(data_g2p, formula(phon_loss_z ~ logfreq_z + phon_len_z), 'logfreq_z')
plot.by.lang(pc.fr)
ggsave("figs-final/corr_pc_fr_g2p.png", width = 6, height = 4)

mi.fr <- model.by.lang(data_g2p, formula(morph_complexity_z ~ logfreq_z), 'logfreq_z')
mi.fr.lem <- model.by.lang(data_base_g2p, formula(morph_complexity_z ~ logfreq_z), 'logfreq_z')
plot.by.lang.2(mi.fr.lem, mi.fr, 'By Lexeme', 'By Word')
ggsave("figs-final/corr_mi_fr_g2p.png", width = 6, height = 4)

wl.fr <- model.by.lang(data_g2p, formula(phon_len_z ~ logfreq_z), 'logfreq_z')
plot.by.lang.sig(wl.fr)
ggsave("figs-final/corr_wl_fr_g2p.png", width = 6, height = 4)

mi.wl <- model.by.lang(data_g2p, formula(morph_complexity_z ~ phon_len_z + logfreq_z), 'phon_len_z')
mi.wl.lem <- model.by.lang(data_base_g2p, formula(morph_complexity_z ~ phon_len_z + logfreq_z), 'phon_len_z')
plot.by.lang.2(mi.wl.lem, mi.wl, 'By Lexeme', 'By Word')
ggsave("figs-final/corr_mi_wl_g2p.png", width = 6, height = 4)

mi.fr <- model.by.lang(data_g2p, formula(morph_complexity_z ~ logfreq_z + phon_len_z), 'logfreq_z')
mi.fr.lem <- model.by.lang(data_base_g2p, formula(morph_complexity_z ~ logfreq_z + phon_len_z), 'logfreq_z')
plot.by.lang.2(mi.fr.lem, mi.fr, 'By Lexeme', 'By Word')
```

# MI ~ PC + FR + WL
```{r mipc-mod2}
mi_pc_mod2 <- lmer(
  morph_complexity_z ~ phon_loss_z + logfreq_z + mean_pc_z + phon_len_z + mean_wl_z + (1 + phon_len_z + phon_loss_z + logfreq_z | lang),
  data=data_g2p,
  REML = FALSE,
  control=lmerControl(optimizer="bobyqa")
)
```

```{r mipc2}
summary(mi_pc_mod2)
tab_model(mi_pc_mod2)
```

```{r mipc-lem-mod2}
mi_pc_lem_mod2 <- lmer(
  morph_complexity_z ~ phon_loss_z + logfreq_z + mean_pc_z + phon_len_z + mean_wl_z + (1 + phon_len_z + phon_loss_z + logfreq_z | lang),
  data=data_base_g2p,
  REML = FALSE,
  control=lmerControl(optimizer="bobyqa")
)
```

```{r mipc-lem2}
summary(mi_pc_lem_mod2)
tab_model(mi_pc_lem_mod2)
```

# MI ~ PC + FR
```{r mipc-mod}
mi_pc_mod <- lmer(
  morph_complexity_z ~ phon_loss_z + logfreq_z + mean_pc_z + (1 + phon_loss_z + logfreq_z | lang),
  data=data_g2p,
  REML = FALSE,
  control=lmerControl(optimizer="bobyqa")
)
```

```{r mipc}
summary(mi_pc_mod)
tab_model(mi_pc_mod)
```

```{r mipc-lem-mod}
mi_pc_lem_mod <- lmer(
  morph_complexity_z ~ phon_loss_z + logfreq_z + mean_pc_z + (1 + phon_loss_z + logfreq_z | lang),
  data=data_base_g2p,
  REML = FALSE,
  control=lmerControl(optimizer="bobyqa")
)
```

```{r mipc-lem}
summary(mi_pc_lem_mod)
tab_model(mi_pc_lem_mod)
```

# PC ~ WL
```{r pcwl-mod}
pc_wl_mod <- lmer(
  phon_loss_z ~ phon_len_z + mean_wl_z + (1 + phon_len_z | lang),
  data=data_g2p,
  REML = FALSE
)
```

```{r pcwl}
summary(pc_wl_mod)
tab_model(pc_wl_mod)
```

```{r pcwl.pim}
data_words_pim <- data_words_pim %>% group_by(lang) %>% mutate(
  mean_pc = mean(phoneme_loss),
  mean_wl = mean(phoneme_len),
) %>% ungroup()

pc_wl_mod_pim <- lmer(
  phoneme_loss ~ phoneme_len + mean_wl + (1 + phoneme_len | lang),
  data=data_words_pim,
  REML = FALSE
)
summary(pc_wl_mod_pim)
tab_model(pc_wl_mod_pim)
```

# PC ~ FR + WL
```{r pcfr-mod}
pc_fr_mod <- lmer(
  phon_loss_z ~ logfreq_z + phon_len_z + mean_wl_z + (1 + logfreq_z + phon_len_z | lang),
  data=data_g2p,
  REML = FALSE
)
```

```{r pcfr}
summary(pc_fr_mod)
tab_model(pc_fr_mod)
```

# MI ~ FR
```{r mifr-mod}
mi_fr_mod <- lmer(
  morph_complexity_z ~ logfreq_z + (1 + logfreq_z | lang),
  data=data_g2p,
  REML = FALSE
)
```

```{r mifr}
summary(mi_fr_mod)
tab_model(mi_fr_mod)
```

```{r mifr-lem-mod}
mi_fr_lem_mod <- lmer(
  morph_complexity_z ~ logfreq_z + (1 + logfreq_z | lang),
  data=data_base_g2p,
  REML = FALSE
)
```

```{r mifr-lem}
summary(mi_fr_lem_mod)
tab_model(mi_fr_lem_mod)
```

# MI ~ FR + WL
```{r mifr-mod2}
mi_fr_mod2 <- lmer(
  morph_complexity_z ~ logfreq_z + phon_len_z + mean_wl_z + (1 + logfreq_z + phon_len_z | lang),
  data=data_g2p,
  REML = FALSE
)
```

```{r mifr2}
summary(mi_fr_mod2)
tab_model(mi_fr_mod2)
```

```{r mifr-lem-mod2}
mi_fr_lem_mod2 <- lmer(
   morph_complexity_z ~ logfreq_z + phon_len_z + mean_wl_z + (1 + logfreq_z + phon_len_z | lang),
  data=data_base_g2p,
  REML = FALSE
)
```

```{r mifr-lem2}
summary(mi_fr_lem_mod2)
tab_model(mi_fr_lem_mod2)
```

# WL ~ FR
```{r wlfr-mod}
wl_fr_mod <- lmer(
  phon_len_z ~ logfreq_z + (1 + logfreq_z | lang),
  data=data_g2p,
  REML = FALSE
)
```

```{r wlfr}
summary(wl_fr_mod)
tab_model(wl_fr_mod)
```

# MI ~ WL + FR
```{r miwl-mod}
mi_wl_mod <- lmer(
  morph_complexity_z ~ phon_len_z + mean_wl_z + logfreq_z + (1 + logfreq_z + phon_len_z | lang),
  data=data_g2p,
  REML = FALSE
)
```

```{r miwl}
summary(mi_wl_mod)
tab_model(mi_wl_mod)
```

```{r miwl-lem-mod}
mi_wl_lem_mod <- lmer(
  morph_complexity_z ~ phon_len_z + mean_wl_z + logfreq_z + (1 + logfreq_z + phon_len_z | lang),
  data=data_base_g2p,
  REML = FALSE
)
```

```{r miwl-lem}
summary(mi_wl_lem_mod)
tab_model(mi_wl_lem_mod)
```

# Language Plots

```{r lp}
pc_means <- data_g2p %>% group_by(lang) %>% summarise(
    mean_len = mean(phon_len),
    mean_pc = mean(phon_loss)
    )



data_pim %>% ggplot(aes(x = val_loss, y = avg_len)) +
  geom_text(aes(label = lang)) +
  geom_text(data=pc_means, aes(label = lang, x = mean_pc, y = mean_len)) +
  geom_smooth(color = "#482C7B", linetype=2) +
  geom_smooth(method='lm', color = "#482C7B") +
  geom_smooth(data=pc_means, aes(x = mean_pc, y = mean_len), color = "#FF6B00", linetype=2) +
  geom_smooth(data=pc_means, aes(x = mean_pc, y = mean_len), method='lm', color = "#FF6B00") +
  theme_hc() +
  scale_x_log10() +
  ylab("Average Length (# IPA Tokens)") +
  xlab("Bits Per Phoneme")

ggsave("figs-final/pim.png", width = 6, height = 4)

plot_across_langs(data_base_g2p, phon_len, morph_complexity, "Word Length", "Morphological Irregularity")
ggsave("figs-final/mi_wl_g2p_b.png", width = 6, height = 4)

plot_across_langs(data_base_g2p, phon_loss, morph_complexity, "Phonotactic Complexity", "Morphological Irregularity")
ggsave("figs-final/mi_pc_g2p_b.png", width = 6, height = 4)
```